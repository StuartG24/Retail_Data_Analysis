{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actions\n",
    "- Create a PDF\n",
    "- Include citations and bibliography\n",
    "- Appendices for detiled code and output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- ?? high-level summary of conclusions\n",
    "- ?? report objectives etc??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives & Approach\n",
    "\n",
    "The purpose of this report is to describe the findings of a data analysis of a provided dataset of customer product review information for a snapshot of US sales activity for the JC Penney retail organisation. The report is also designed to meet the stated assignment objective of \"use the data provided to demonstrate your Python data manipulation skills\".\n",
    "\n",
    "This report is structured to provide an initial summary of the main observations and then detail the supporting detail, largely following the data CRISP-DM analysis sequence. \n",
    "\n",
    "In each section of the report there is:\n",
    "- a text description of what is being achieved and main observations\n",
    "- a Python code block, with explanatory comments\n",
    "- execution results\n",
    "\n",
    "Some of the code and execution results are included in the appendices so that the main report does not become too lengthy.\n",
    "\n",
    "***!! your code must be working, correct, and well commented and shows an appreciation of style, efficiency and reliability. All choices for methods and structures are concisely justified and alternatives are given well thought considerations.***\n",
    "\n",
    "### CRISP-DM\n",
    "\n",
    "The approach to the analysis follows the first four parts of the six stage \"CRoss-Industry Standard Process for Data Mining' (CRISP-DM) process. ***[!! See citations url and (Ncr et al., 1999) !!]***. In summary, this process is:\n",
    "\n",
    "1. Business Understanding: Define project objectives and requirements by collaborating with stakeholders\n",
    "2. Data Understanding: Collect and explore data, analyzing its characteristics and quality\n",
    "3. Data Preparation: Clean, handle missing values, and transform variables to create a structured dataset\n",
    "4. Modeling: Apply various techniques such as machine learning algorithms or statistical models to the prepared data\n",
    "5. Evaluation: Rigorously assess models based on predefined criteria, including performance and reliability\n",
    "6. Deployment: Integrate successful models into existing systems and monitor their effectiveness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General setup and imports used throughout the Jupyter Notebook\n",
    "#\n",
    "\n",
    "# Libraries For file handling and dataframes\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "import pandas as pd \n",
    "\n",
    "# Libraries ....\n",
    "## cccccc\n",
    "\n",
    "# Variables used throughout the notebook\n",
    "DATA_DIRECTORY = 'JCPenney_Data_Original'  # Designated data folder within the current working directory\n",
    "\n",
    "# A simple utility function to obtain and summarise key elements of a provided dataframe\n",
    "#\n",
    "def print_file_summary(data_frame):\n",
    "    # Create a temporary df and ensure no lists remain, so that unique items can be identified for uniquness\n",
    "    temp_df = data_frame.copy()\n",
    "    temp_df = temp_df.map(lambda cell: str(cell) if isinstance(cell, list) else cell)\n",
    "    \n",
    "    # Calculate some \n",
    "    summary_of_df = pd.DataFrame({'Count': data_frame.count(),\n",
    "                                 'Missing': data_frame.isnull().sum(), 'Empty': 0,\n",
    "                                 'Unique': temp_df.nunique(),\n",
    "                                 'Type': data_frame.dtypes, \n",
    "                                 'String': 0, 'Int': 0, 'Float': 0, 'List': 0\n",
    "                                 })\n",
    "    summary_of_df['Empty'] = (data_frame == '').sum()\n",
    "    summary_of_df['String'] = data_frame.map(lambda cell: isinstance(cell, str)).sum()\n",
    "    summary_of_df['Int'] = data_frame.map(lambda cell: isinstance(cell, int)).sum()\n",
    "    summary_of_df['Float'] = data_frame.map(lambda cell: isinstance(cell, float)).sum()\n",
    "    summary_of_df['List'] = data_frame.map(lambda cell: isinstance(cell, list)).sum()\n",
    "\n",
    "    display(summary_of_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "- 1. Data Exploration - Explore the data and show you understand its structure and relations\n",
    "- 2. Data Validation - Check the quality of the data. Is it complete? Are there obvious errors?\n",
    "- x. Data Preparation - Addresss the issues identified, supliment/augment the data, restructure\n",
    "    - Select Data - which to use and which to exclude .. with reasoning\n",
    "    - Clean Data - 'correct, impute, remove' ...\n",
    "    - Construct Data - derive new attributes as needed/helpful\n",
    "    - Integrate Data - new datasets, augment, other sources\n",
    "    - Format Data - reformat as needed, eg string to numeric, dates, categorical  \n",
    "\n",
    "- ?? data structure, size\n",
    "- ?? data quality, missing etc\n",
    "\n",
    "#### Data Completeness\n",
    " - Missing Data - Identify and resolve by removal or inferring. Imputation and visualisation, examining descriptive stats\n",
    "- Noisy - Random errors, eg from faulty sensors, data transmission\n",
    "- Duplicates - Identify and eliminate duplicates, redundancy. NB: Can occur after data integration\n",
    "- Inconsistency - Data items don't align, eg DOB and age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structure & Content\n",
    "\n",
    "The provided data sources for this analysis of JC Penney consists of two JSON files and three CSV files:\n",
    "- jcpenney_products.json, jcpenney_reviewers.json; and\n",
    "- products.csv, reviews.csv, users.csv.\n",
    "\n",
    "It was not immediately obvious what the relationships between the two types of data was but the json and CSV files appear to be partial duplicates of each other; also the three CSV files hold slightly less information (eg sales price is missing from the csv files). The CSV files appear to be a first attempt to extract data from the json files (eg the json products file has a JSON field holding multiple user reviews and this has looks to have been extracted to prepare the reviews.csv file).\n",
    "\n",
    "Given the above, the approach used in this analysis was to go back to the 'orginal' JSON files and work from these but with a sanity check against the three CSV files to make sure no data was missed or inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources Overview - JSON\n",
    "\n",
    "It is assumed that the data is a snapshot extract of sales information from JC Penney databases and the bulk of this has been flattened and used to create the jcpenney_products.json file with the jcpenney_reviewers.json file providing details of individual customers.\n",
    "\n",
    "The two tables below show the data items and key counts for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Summary for: jcpenney_products.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>6044</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_title</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6002</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>543</td>\n",
       "      <td>5620</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_price</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>2166</td>\n",
       "      <td>1037</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_price</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2063</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>636</td>\n",
       "      <td>1169</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_tree</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>636</td>\n",
       "      <td>1997</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_product_rating</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_url</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_image_urls</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>6519</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_number_reviews</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bought With</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Count  Missing  Empty  Unique     Type  String   Int  \\\n",
       "uniq_id                  7982        0      0    7982   object    7982     0   \n",
       "sku                      7982        0     67    6044   object    7982     0   \n",
       "name_title               7982        0      0    6002   object    7982     0   \n",
       "description              7982        0    543    5620   object    7982     0   \n",
       "list_price               7982        0   2166    1037   object    7982     0   \n",
       "sale_price               7982        0     18    2063   object    7982     0   \n",
       "category                 7982        0    636    1169   object    7982     0   \n",
       "category_tree            7982        0    636    1997   object    7982     0   \n",
       "average_product_rating   7982        0      0     153  float64       0     0   \n",
       "product_url              7982        0      0    7982   object    7982     0   \n",
       "product_image_urls       7982        0    157    6519   object    7982     0   \n",
       "brand                    7982        0      0     721   object    7982     0   \n",
       "total_number_reviews     7982        0      0      22    int64       0  7982   \n",
       "Reviews                  7982        0      0    7982   object       0     0   \n",
       "Bought With              7982        0      0    7982   object       0     0   \n",
       "\n",
       "                        Float  List  \n",
       "uniq_id                     0     0  \n",
       "sku                         0     0  \n",
       "name_title                  0     0  \n",
       "description                 0     0  \n",
       "list_price                  0     0  \n",
       "sale_price                  0     0  \n",
       "category                    0     0  \n",
       "category_tree               0     0  \n",
       "average_product_rating   7982     0  \n",
       "product_url                 0     0  \n",
       "product_image_urls          0     0  \n",
       "brand                       0     0  \n",
       "total_number_reviews        0     0  \n",
       "Reviews                     0  7982  \n",
       "Bought With                 0  7982  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 Rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>name_title</th>\n",
       "      <th>description</th>\n",
       "      <th>list_price</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>category</th>\n",
       "      <th>category_tree</th>\n",
       "      <th>average_product_rating</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_image_urls</th>\n",
       "      <th>brand</th>\n",
       "      <th>total_number_reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Bought With</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>2.625</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'User': 'fsdv4141', 'Review': 'You never hav...</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93e5272c51d8cce02597e3ce67b7ad0a</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>3.000</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'User': 'tpcu2211', 'Review': 'You never hav...</td>\n",
       "      <td>[bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013e320f2f2ec0cf5b3ff5418d688528</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>view all</td>\n",
       "      <td>jcpenney|women|view all</td>\n",
       "      <td>2.625</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'User': 'pcfg3234', 'Review': 'You never hav...</td>\n",
       "      <td>[3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id           sku  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       "1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       "2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
       "\n",
       "                                    name_title  \\\n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "2  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "\n",
       "                                         description list_price sale_price  \\\n",
       "0  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       "1  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       "2  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       "\n",
       "        category                 category_tree  average_product_rating  \\\n",
       "0  alfred dunner  jcpenney|women|alfred dunner                   2.625   \n",
       "1  alfred dunner  jcpenney|women|alfred dunner                   3.000   \n",
       "2       view all       jcpenney|women|view all                   2.625   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "2  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "\n",
       "                                  product_image_urls          brand  \\\n",
       "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "2  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "\n",
       "   total_number_reviews                                            Reviews  \\\n",
       "0                     8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
       "1                     8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
       "2                     8  [{'User': 'pcfg3234', 'Review': 'You never hav...   \n",
       "\n",
       "                                         Bought With  \n",
       "0  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
       "1  [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  \n",
       "2  [3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the JSON product file and examine the format and content\n",
    "# NB: Use pandas json load to directly create a dataframe\n",
    "\n",
    "# Products file source\n",
    "file_name = 'jcpenney_products.json'\n",
    "file_path = os.path.join(os.getcwd(), DATA_DIRECTORY, file_name)\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f'File not found: {file_path}')\n",
    "\n",
    "# File load into a Pandas dataframe, retained and not amended\n",
    "source_jcp_products_df = pd.read_json(file_path, lines=True)\n",
    "                    \n",
    "# Initial look at the file and data fields\n",
    "print(f'File Summary for: {file_name}')\n",
    "print_file_summary(source_jcp_products_df)\n",
    "print(f'First 3 Rows')\n",
    "display(source_jcp_products_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Summary for: jcpenney_reviewers.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Username</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviewed</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4030</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count  Missing  Empty  Unique    Type  String  Int  Float  List\n",
       "Username   5000        0      0    4999  object    5000    0      0     0\n",
       "DOB        5000        0      0      52  object    5000    0      0     0\n",
       "State      5000        0      0      57  object    5000    0      0     0\n",
       "Reviewed   5000        0      0    4030  object       0    0      0  5000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 Rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>DOB</th>\n",
       "      <th>State</th>\n",
       "      <th>Reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>31.07.1983</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>27.07.1998</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>08.08.1950</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Username         DOB          State                            Reviewed\n",
       "0  bkpn1412  31.07.1983         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
       "1  gqjs4414  27.07.1998  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3]\n",
       "2  eehe1434  08.08.1950          Idaho                                  []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the JSON reviewers file and examine the format and content\n",
    "# NB: Use pandas json load to directly create a dataframe\n",
    "\n",
    "# Reviewers file source\n",
    "file_name = 'jcpenney_reviewers.json'\n",
    "file_path = os.path.join(os.getcwd(), DATA_DIRECTORY, file_name)\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f'File not found: {file_path}')\n",
    "\n",
    "# File load into a Pandas dataframe, retained and not amended\n",
    "source_jcp_reviewers_df = pd.read_json(file_path, lines=True)\n",
    "                    \n",
    "# Initial look at the file and data fields\n",
    "print(f'File Summary for: {file_name}')\n",
    "print_file_summary(source_jcp_reviewers_df)\n",
    "print(f'First 3 Rows')\n",
    "display(source_jcp_reviewers_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources Overview - CSV\n",
    "\n",
    "***TODO: Decode and compare to JSON***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure\n",
    "\n",
    "Looking at the content of the two files the underlieing data structure described below has been assumed.\n",
    "\n",
    "Sales Activity - 7982 rows in the file jcpenney_products.json\n",
    "- uniq_id: this uniquely identifies each of the 7982 rows. A random string\n",
    "- list_price: assumed to be the price at the point of sale in $\n",
    "    ***?? prices consistent accross channels, any pattern?, 18 missing ***\n",
    "    *** convert to numeric**\n",
    "- category_tree: breakdown of the stock catgeorisation eg 'jcpenny|women|skechers' \n",
    "- category: lowest level of category \n",
    "    *** drop this? why unique 1169 vs 1997 for the treee also ?? not same match to SKU etc eg the use of 'view all' ?? ***\n",
    "- average_product_rating: rating 1 to 5 \n",
    "    *** a float with some wierd values .. should be categorical? convert? ***,\n",
    "    *** is this a calculated average from individual reviews? check***\n",
    "- product_url: link to website product details \n",
    "    *** 7982 And these are unique to the review, not the product ... why? ***\n",
    "    *** need us vpn to use this? ***\n",
    "- product_image_urls: link to product image \n",
    "    *** 6519, more images than product number, less than product URL ***\n",
    "- Bought with: series of items linked using the uniq_id \n",
    "    *** check these link up? and rename ***\n",
    "    ***what is is useful for?***\n",
    "\n",
    "Stock / Product - 6044 unique items in the file jcpenney_products.json\n",
    "- sku: a unique 'Stock Keeping Unit', format 'xxnnnnnnnnnn', 6044 discrete values\n",
    "    ***?? are all references valid format, 67 seem odd or blank or not standard format***\n",
    "- name_title: name of the stock item\n",
    "    ***?? uniques count about 38 less than SKU***\n",
    "- description: long description of the item\n",
    "    ***?? uniques count about 400 less than name***\n",
    "- list_price: assumed to be the standard item price in $\n",
    "    ***?? prices appear to be different for some stock, 2166 missing ***\n",
    "    *** convert to numeric**\n",
    "- brand: manufacturer brand name eg 'Alfred Dunner'\n",
    "\n",
    "Customer Reviews - unique items in the file jcpenney_products.json\n",
    "- total_number_reviews: number of customer reviews for each uniq_id / Sales Channel Activity\n",
    "    *** is this needed, or just for a cross-check later? convert to numeric**\n",
    "- Reviews: a json item with several customer reviews, each with: user, review text, score (1 to 5) \n",
    "\n",
    "Reviewers - 5000 rows in the filejcpenney_reviewers.json ***4999 in the CSV file***\n",
    "- Username: unique string id\n",
    "    ***4999 uniques, so a duplicate?**\n",
    "- DOB: String date\n",
    "    ***convert to date***, ***look at date range for months, days ... only 52 unique!!***\n",
    "- State: string name for the state\n",
    "    ***here 57 unique items, but only 50 us states?**\n",
    "- Reviewed: a list of the uniq_id / Sales Activity items reviewed\n",
    "    ***4030 unique vs 5000, also appear to be some empty lists***\n",
    "\n",
    "### Links\n",
    "?? Link/Cross-Ref\n",
    "- 'Stock Keeping Unit' (https://en.wikipedia.org/wiki/Stock_keeping_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Initial Working Dataframes\n",
    "\n",
    "The two initial source dataframes \"source_jcp_products_df\" and \"sourcejcp_reviewers_df\" were used to create three new dataframes for validation and manipulation:\n",
    "- xxx sales_activity_df\n",
    "- Customer Reviews: customer_reviews_df for all individual customer reviews, with uniq_id to link back to the Sales Activity\n",
    "- xxx customers_df\n",
    "- xxx ??? others\n",
    "\n",
    "?? Validate each user against the users data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Activity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock / Products\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customers\n",
    "\n",
    "The \"jcpenney_reviewers.json\" contains a list of reviewers or perhaps what can be considered as customers. This data was loaded and a new customer dataframe was created with each having a list of uniq_ids that link back to the sales activiy.\n",
    "\n",
    "Two entries were duplicated, with the same customer-is but having different dates of birth and states, and linked to different sales activities.\n",
    "\n",
    "***rename code for one to continue to use??***\n",
    "\n",
    "The date of birth detsils look they have been artifically generated, there is a sequence from 26 July to 8 August with decreasing year. Therefore the field has been dropped and not used for further analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Customers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>DOB</th>\n",
       "      <th>State</th>\n",
       "      <th>Reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>dqft3311</td>\n",
       "      <td>28.07.1995</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>[5f280fb338485cfc30678998a42f0a55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>dqft3311</td>\n",
       "      <td>03.08.1969</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>[571b86d307f94e9e8d7919b551c6bb52]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Username         DOB       State                            Reviewed\n",
       "731   dqft3311  28.07.1995   Tennessee  [5f280fb338485cfc30678998a42f0a55]\n",
       "2619  dqft3311  03.08.1969  New Mexico  [571b86d307f94e9e8d7919b551c6bb52]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates Count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-08-08</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951-08-08</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952-08-07</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-08-07</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954-08-07</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1955-08-07</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956-08-06</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1957-08-06</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1958-08-06</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1959-08-06</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1960-08-05</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1961-08-05</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1962-08-05</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1963-08-05</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964-08-04</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1965-08-04</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1966-08-04</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1967-08-04</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1968-08-03</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1969-08-03</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1970-08-03</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1971-08-03</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1972-08-02</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1973-08-02</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1974-08-02</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1975-08-02</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1976-08-01</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1977-08-01</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1978-08-01</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1979-08-01</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1980-07-31</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1981-07-31</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1982-07-31</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1983-07-31</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1984-07-30</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1985-07-30</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1986-07-30</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1987-07-30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1988-07-29</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1989-07-29</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1990-07-29</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1991-07-29</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1992-07-28</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1993-07-28</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1994-07-28</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1995-07-28</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1996-07-27</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1997-07-27</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1998-07-27</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1999-07-27</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2000-07-26</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2001-07-26</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DOB  counts\n",
       "0  1950-08-08      99\n",
       "1  1951-08-08      95\n",
       "2  1952-08-07     103\n",
       "3  1953-08-07     112\n",
       "4  1954-08-07      79\n",
       "5  1955-08-07      93\n",
       "6  1956-08-06      96\n",
       "7  1957-08-06      93\n",
       "8  1958-08-06      96\n",
       "9  1959-08-06      94\n",
       "10 1960-08-05     107\n",
       "11 1961-08-05     101\n",
       "12 1962-08-05     106\n",
       "13 1963-08-05     106\n",
       "14 1964-08-04     107\n",
       "15 1965-08-04     106\n",
       "16 1966-08-04      94\n",
       "17 1967-08-04      90\n",
       "18 1968-08-03      91\n",
       "19 1969-08-03      99\n",
       "20 1970-08-03     101\n",
       "21 1971-08-03      90\n",
       "22 1972-08-02      91\n",
       "23 1973-08-02     102\n",
       "24 1974-08-02     102\n",
       "25 1975-08-02     106\n",
       "26 1976-08-01      87\n",
       "27 1977-08-01      97\n",
       "28 1978-08-01      79\n",
       "29 1979-08-01     106\n",
       "30 1980-07-31      99\n",
       "31 1981-07-31      85\n",
       "32 1982-07-31      98\n",
       "33 1983-07-31      99\n",
       "34 1984-07-30      80\n",
       "35 1985-07-30     100\n",
       "36 1986-07-30      83\n",
       "37 1987-07-30      99\n",
       "38 1988-07-29     100\n",
       "39 1989-07-29      81\n",
       "40 1990-07-29     103\n",
       "41 1991-07-29     104\n",
       "42 1992-07-28     101\n",
       "43 1993-07-28      96\n",
       "44 1994-07-28      86\n",
       "45 1995-07-28      95\n",
       "46 1996-07-27      81\n",
       "47 1997-07-27      97\n",
       "48 1998-07-27     111\n",
       "49 1999-07-27     104\n",
       "50 2000-07-26      90\n",
       "51 2001-07-26      80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers by State:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Florida</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Guam</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hawaii</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Idaho</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Indiana</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kentucky</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Louisiana</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Maine</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Minor Outlying Islands</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mississippi</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Missouri</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Montana</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Nevada</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>New Mexico</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>New York</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>North Carolina</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>North Dakota</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Northern Mariana Islands</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Ohio</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Oregon</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>South Carolina</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>South Dakota</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Texas</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Utah</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Vermont</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Washington</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       State  counts\n",
       "0                    Alabama      95\n",
       "1                     Alaska      94\n",
       "2             American Samoa      86\n",
       "3                    Arizona      71\n",
       "4                   Arkansas      92\n",
       "5                 California      99\n",
       "6                   Colorado      85\n",
       "7                Connecticut      82\n",
       "8                   Delaware     106\n",
       "9       District of Columbia      83\n",
       "10                   Florida      89\n",
       "11                   Georgia      79\n",
       "12                      Guam      73\n",
       "13                    Hawaii      88\n",
       "14                     Idaho      79\n",
       "15                  Illinois      69\n",
       "16                   Indiana      86\n",
       "17                      Iowa      94\n",
       "18                    Kansas      90\n",
       "19                  Kentucky      99\n",
       "20                 Louisiana      80\n",
       "21                     Maine      94\n",
       "22                  Maryland      77\n",
       "23             Massachusetts     107\n",
       "24                  Michigan      76\n",
       "25                 Minnesota      77\n",
       "26    Minor Outlying Islands      92\n",
       "27               Mississippi      94\n",
       "28                  Missouri      84\n",
       "29                   Montana      97\n",
       "30                  Nebraska      90\n",
       "31                    Nevada      90\n",
       "32             New Hampshire      83\n",
       "33                New Jersey     101\n",
       "34                New Mexico      96\n",
       "35                  New York      83\n",
       "36            North Carolina      68\n",
       "37              North Dakota      85\n",
       "38  Northern Mariana Islands     102\n",
       "39                      Ohio      81\n",
       "40                  Oklahoma     100\n",
       "41                    Oregon      96\n",
       "42              Pennsylvania      86\n",
       "43               Puerto Rico      83\n",
       "44              Rhode Island      93\n",
       "45            South Carolina      77\n",
       "46              South Dakota      79\n",
       "47                 Tennessee      89\n",
       "48                     Texas      83\n",
       "49       U.S. Virgin Islands      95\n",
       "50                      Utah      80\n",
       "51                   Vermont     103\n",
       "52                  Virginia      96\n",
       "53                Washington      94\n",
       "54             West Virginia      80\n",
       "55                 Wisconsin      84\n",
       "56                   Wyoming      86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for customers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_id_list</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4030</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  Missing  Empty  Unique    Type  String  Int  Float  List\n",
       "customer_id    5000        0      0    4999  object    5000    0      0     0\n",
       "state          5000        0      0      57  object    5000    0      0     0\n",
       "uniq_id_list   5000        0      0    4030  object       0    0      0  5000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>state</th>\n",
       "      <th>uniq_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id          state                        uniq_id_list\n",
       "0    bkpn1412         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
       "1    gqjs4414  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3]\n",
       "2    eehe1434          Idaho                                  []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish an initial customers  dataframe\n",
    "\n",
    "# Create a new dataframe for all cutomer reviews\n",
    "customers_df = source_jcp_reviewers_df.copy()\n",
    "\n",
    "# Identify duplicate cutomers\n",
    "duplicates_flag = customers_df.duplicated(subset=['Username'], keep=False)\n",
    "duplicated = customers_df[duplicates_flag]\n",
    "print(f'Duplicated Customers:')\n",
    "display(duplicated)\n",
    "# TODO: What action to take, drop or rename?\n",
    "\n",
    "# DOB convert to date format and examine the dates used\n",
    "customers_df['DOB'] = pd.to_datetime(customers_df['DOB'], dayfirst=True, errors='coerce')\n",
    "dates = customers_df.groupby('DOB').size().reset_index(name='counts')\n",
    "print(f'Dates Count:')\n",
    "display(dates)\n",
    "# Drop the date has looks artificaly generated and so of no real use in later analysis\n",
    "customers_df = customers_df.drop('DOB', axis=1)\n",
    "\n",
    "# States validate\n",
    "states = customers_df.groupby('State').size().reset_index(name='counts')\n",
    "print(f'Customers by State:')\n",
    "display(states)\n",
    "\n",
    "# Reviewed validate\n",
    "# TODO: x-check these to sails activity and to reviews to make sure consistent\n",
    "\n",
    "# Tidy up\n",
    "del duplicates_flag\n",
    "del duplicated\n",
    "del dates\n",
    "del states\n",
    "\n",
    "# Rename customer column names and validate content for each\n",
    "customers_df = customers_df.rename(columns={'Username': 'customer_id', \n",
    "                                            'State': 'state',\n",
    "                                            'Reviewed': 'uniq_id_list'})\n",
    "\n",
    "# Print the file and data fields\n",
    "print(f'Summary for customers')\n",
    "print_file_summary(customers_df)\n",
    "print(f'First 3 rows')\n",
    "display(customers_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Reviews\n",
    "\n",
    "In the \"jcpenney_products.json\" file the series of JSON encoded review details were extracted and a new customer reviews dataframe was created, with individual review records linked back to the sales activiy using the uniq_id. The table below summarises the fields decoded and key counts.\n",
    "\n",
    "There are a total of 39,063 reviews but only 29,464 appear to be unique review comments. Further analysis found that 15,535 (40%) of reviews were used by several customers, worst case being several instances of 18 customers using the same comments. This could be because the sample data has been automaticaly generated or that customer ids are being created to generate false reviews. This data has not been dropped from the dataset, although later sentiment analysis of the reviews could be misleading.\n",
    "\n",
    "The scores for reviews in the CSV file have a large number of zero vslues (11,265 out of 39,063) and a quick examination showed that many scores differ between the JSON and CSV source. Therefore the \"reviews.CSV\" data source was rejected and only the JSON source was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for customer reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4993</td>\n",
       "      <td>object</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29464</td>\n",
       "      <td>object</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Count  Missing  Empty  Unique    Type  String    Int  Float  List\n",
       "uniq_id      39063        0      0    7982  object   39063      0      0     0\n",
       "customer_id  39063        0      0    4993  object   39063      0      0     0\n",
       "review       39063        0      0   29464  object   39063      0      0     0\n",
       "score        39063        0      0       5   int64       0  39063      0     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>krpz1113</td>\n",
       "      <td>Good quality fabric. Perfect fit. Washed very ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>mbmg3241</td>\n",
       "      <td>I do not normally wear pants or capris that ha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id customer_id  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d    fsdv4141   \n",
       "1  b6c0b6bea69c722939585baeac73c13d    krpz1113   \n",
       "2  b6c0b6bea69c722939585baeac73c13d    mbmg3241   \n",
       "\n",
       "                                              review  score  \n",
       "0  You never have to worry about the fit...Alfred...      2  \n",
       "1  Good quality fabric. Perfect fit. Washed very ...      4  \n",
       "2  I do not normally wear pants or capris that ha...      4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish an initial customer reviews dataframe\n",
    "# By extracting the series of JSON reviews originaly in the jcpenney_products.json \n",
    "\n",
    "# Create a new dataframe for all cutomer reviews\n",
    "customer_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through all rows of the orgonal products data, to extract and decode the series of JSON data\n",
    "# Create customer review rows, each using a foreign key uniq_id for the relevant sales activity\n",
    "# TODO: This takes 4 seconds to run, replace with a more efficient approach\n",
    "for next_row in source_jcp_products_df.itertuples(index=False):\n",
    "    temp_reviews = next_row.Reviews\n",
    "    #print(f'UI: {next_row.uniq_id}, {temp_reviews}, {type(temp_reviews)}')\n",
    "    temp_dict_string = json.dumps(temp_reviews)\n",
    "    temp_reviews_df = pd.DataFrame(json.loads(temp_dict_string))\n",
    "    temp_reviews_df.insert(0, 'uniq_id', next_row.uniq_id)\n",
    "    #print(temp_reviews_df)\n",
    "    customer_reviews_df = pd.concat([customer_reviews_df, temp_reviews_df])\n",
    "\n",
    "# Cross-check the customer_id to the customers data frame to make sure all exist\n",
    "if not customer_reviews_df['User'].isin(customers_df['customer_id']).all():\n",
    "    print(f'Error: Not all customers setup in customers list')\n",
    "\n",
    "# Tidy up\n",
    "del temp_reviews\n",
    "del temp_dict_string\n",
    "del temp_reviews_df\n",
    "\n",
    "# Rename customer column names and validate content for each\n",
    "customer_reviews_df = customer_reviews_df.rename(columns={'User': 'customer_id', \n",
    "                                                          'Review': 'review', 'Score': 'score'})\n",
    "\n",
    "# Initial look at the file and data fields\n",
    "print(f'Summary for customer reviews')\n",
    "print_file_summary(customer_reviews_df)\n",
    "print(f'First 3 rows')\n",
    "display(customer_reviews_df.head(3))\n",
    "\n",
    "# ?? create products ... sales activity file without reviews\n",
    "# Ensure a valid customer record exists in the customers dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of a total of 39063 reviews 15535 are duplicates.\n",
      "Or approximately 40%\n",
      "Several worst case situations with 18 customers using the same review comments.\n"
     ]
    }
   ],
   "source": [
    "# Look at how many reviews are duplicates and how many customers are linked to these\n",
    "\n",
    "duplicates_by_customer = customer_reviews_df.groupby('review')['customer_id'].size().reset_index(name='cust_count')\n",
    "reviews_duplicated = duplicates_by_customer.groupby('cust_count').count().reset_index()\n",
    "\n",
    "count_reviews_single = reviews_duplicated[reviews_duplicated['cust_count'] == 1]\n",
    "count_reviews_duplicated = len(customer_reviews_df) - count_reviews_single['review'].sum()\n",
    "max_duplicates = reviews_duplicated['cust_count'].max()\n",
    "\n",
    "print(f'Out of a total of {len(customer_reviews_df)} reviews {count_reviews_duplicated} are duplicates.')\n",
    "print(f'Or approximately {((count_reviews_duplicated/len(customer_reviews_df)) * 100):.0f}%')\n",
    "print(f'Several worst case situations with {max_duplicates} customers using the same review comments.')\n",
    "\n",
    "# Tidy up\n",
    "del duplicates_by_customer\n",
    "del reviews_duplicated\n",
    "del count_reviews_single\n",
    "del count_reviews_duplicated\n",
    "del max_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for customer reviews - CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Uniq_id</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Username</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4993</td>\n",
       "      <td>object</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Review</th>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29463</td>\n",
       "      <td>object</td>\n",
       "      <td>39063</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count  Missing  Empty  Unique    Type  String    Int  Float  List\n",
       "Uniq_id   39063        0      0    7982  object   39063      0      0     0\n",
       "Username  39063        0      0    4993  object   39063      0      0     0\n",
       "Score     39063        0      0       6   int64       0  39063      0     0\n",
       "Review    39063        0      0   29463  object   39063      0      0     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq_id</th>\n",
       "      <th>Username</th>\n",
       "      <th>Score</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>2</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>krpz1113</td>\n",
       "      <td>1</td>\n",
       "      <td>Good quality fabric. Perfect fit. Washed very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>mbmg3241</td>\n",
       "      <td>2</td>\n",
       "      <td>I do not normally wear pants or capris that ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq_id  Username  Score  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       "1  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
       "2  b6c0b6bea69c722939585baeac73c13d  mbmg3241      2   \n",
       "\n",
       "                                              Review  \n",
       "0  You never have to worry about the fit...Alfred...  \n",
       "1  Good quality fabric. Perfect fit. Washed very ...  \n",
       "2  I do not normally wear pants or capris that ha...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare JSON sourced review vs CSV file source\n",
      "Count:  39063 vs 39063\n",
      "Scores with zero: 0 vs 11265\n",
      "Mean:  3.0 vs 1.5\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV reviews file to cross-check against the data extracted from the JSON sourced reviews\n",
    "\n",
    "# Load the reviews .csv file, exit if do not exist or are invalid\n",
    "file_path = os.path.join(os.getcwd(), DATA_DIRECTORY, 'reviews.csv')\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f\"File not found: {file_path}\")\n",
    "source_reviewsCSV_df = pd.read_csv(file_path)\n",
    "\n",
    "# Initial look at the file and data fields\n",
    "print(f'Summary for customer reviews - CSV')\n",
    "print_file_summary(source_reviewsCSV_df)\n",
    "print(f'First 3 rows')\n",
    "display(source_reviewsCSV_df.head(3))\n",
    "\n",
    "# Scores look very different\n",
    "\n",
    "count_zero_scores = source_reviewsCSV_df[source_reviewsCSV_df['Score'] == 0]['Score'].count()\n",
    "count_zero_scoresJSON = customer_reviews_df[customer_reviews_df['score'] == 0]['score'].count()\n",
    "\n",
    "print(f'Compare JSON sourced review vs CSV file source')\n",
    "print(f'Count:  {len(customer_reviews_df)} vs {len(source_reviewsCSV_df)}')\n",
    "print(f'Scores with zero: {count_zero_scoresJSON:.0f} vs {count_zero_scores:.0f}')\n",
    "print(f'Mean:  {customer_reviews_df['score'].mean():.1f} vs {source_reviewsCSV_df['Score'].mean():.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis of reviews\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_categorise(sentiment):\n",
    "    '''\n",
    "    Positive: Compound score >= 0.05\n",
    "    Neutral: Compound score > -0.05 and < 0.05\n",
    "    Negative: Compound score <= -0.05\n",
    "    '''\n",
    "    if sentiment <= -0.05:\n",
    "        return 1\n",
    "    elif sentiment < 0.05:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "review_sentiments = [analyser.polarity_scores(review_text)['compound'] for review_text in customer_reviews_df['review']]\n",
    "customer_reviews_df['sentimentC'] = [sentiment_categorise(x) for x in review_sentiments]\n",
    "customer_reviews_df['sentiment'] = review_sentiments\n",
    "\n",
    "# TODO: Appears to be an inconsistent use of score, some appear to have 1 as best whilst others using 5 as best\n",
    "# TODO: Classify sentiment anlaysis as good, bad, neutral or 1 3 5? Correlate/fit with score? Evidence to support above?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "\n",
    "- 4993 users x-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation\n",
    "\n",
    " 3. Data Visualisation - Gain an overall understanding of the data with visualisations\n",
    "\n",
    "- Initial review, plots etc\n",
    "- Initial observations, insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    " 4. Data Analysis = Set some questions and use the data to answer them\n",
    " 5. Data Augmentation - Add new data from another source to bring new insights to the data you already have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "See the CRISP-DM in the intro\n",
    "- https://www.datascience-pm.com/crisp-dm-2/\n",
    "- (Ncr et al., 1999) ........ Ncr, P.C. et al. (1999) ‘CRISP-DM 1.0’."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
