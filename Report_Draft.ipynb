{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "- ?? high-level summary of conclusions\n",
    "- ?? report objectives etc??\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives & Approach\n",
    "\n",
    "This report describes the findings from an analysis of sales review data for a US retail chain, JCPenney. It is the final assignment in the module: ITNPBD2,  Representing and Manipulating Data and uses several datsets provided, with some suplimentary data to augment this.\n",
    "\n",
    "The report is structured into four sections:\n",
    "- Summary\n",
    "- Data Collation, Exploration & Preparation\n",
    "- Visualation & Initial Analysis\n",
    "- Conclusions\n",
    "\n",
    "### Approach\n",
    "\n",
    "This has primarily been written as a business report, with conclusions and supporting details. However, it also provides details of the analysis approach taken and listings of the Python code used. In order, not to disrupt the flow of the reporting, as much as is possible, the Python code has been put towards the end of report sections **??? or in appendices ??**.\n",
    "\n",
    "I was not totally clear about the relative importance of the assignment objectives and so have attempted to meet the objectives stated below, in order of priority:\n",
    "- Provide a business report to senior managers who are not interested in the detailed approach or source data\n",
    "- Demonstrate that a data science process (here CRISP-DM) has been followed\n",
    "- Demonstrate the use of Python for data manipulation and analysis\n",
    "\n",
    "The original source and timing for the provided datasets is not known and so the following assumptions have been made\n",
    "- Source is from JCP's operational stock and sales systems\n",
    "- The data was extracted in Q3 2023\n",
    "\n",
    "***!! your code must be working, correct, and well commented and shows an appreciation of style, efficiency and reliability. All choices for methods and structures are concisely justified and alternatives are given well thought considerations.***\n",
    "\n",
    "### CRISP-DM\n",
    "\n",
    "The approach to the analysis follows the first four parts of the six stage \"CRoss-Industry Standard Process for Data Mining' (CRISP-DM) process. ***[!! See citations url and (Ncr et al., 1999) !!]***. In summary, this process is:\n",
    "\n",
    "1. Business Understanding: Define project objectives and requirements by collaborating with stakeholders\n",
    "2. Data Understanding: Collect and explore data, analyzing its characteristics and quality\n",
    "3. Data Preparation: Clean, handle missing values, and transform variables to create a structured dataset\n",
    "4. Modeling: Apply various techniques such as machine learning algorithms or statistical models to the prepared data\n",
    "5. Evaluation: Rigorously assess models based on predefined criteria, including performance and reliability\n",
    "6. Deployment: Integrate successful models into existing systems and monitor their effectiveness\n",
    "\n",
    "### Who Are JCPenney?\n",
    "\n",
    "JCPenney (JCP) is a major North American department store chain [Wikipedia](https://en.wikipedia.org/wiki/JCPenney), operating as Penney OpCo LLC. JCP has 656 stores in 49 states plus Puerto Rico according to the [JCP Store Locator](https://www.jcpenney.com/locations/index.html). \n",
    "\n",
    "In 2020, JCP filed for bankruptcy and were purchased by an asset management company, a large number of stores were also closed. Later, in August 2023, JCP announced a major turnaround plan to replace its current website and inventory management systems, as well as make major upgardes to its retails stores. See this article for more details: [Modern Retail Sep 2023](https://www.modernretail.co/operations/jcpenney-is-the-latest-department-store-to-announce-a-major-turnaround-plan/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collation, Exploration & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General setup and imports used throughout the Jupyter Notebook\n",
    "#\n",
    "# Libraries For file handling and dataframes\n",
    "import os\n",
    "import json\n",
    "from IPython.display import display\n",
    "import pandas as pd \n",
    "\n",
    "# Libraries ....\n",
    "## cccccc\n",
    "\n",
    "# Variables used throughout the notebook\n",
    "DATA_DIRECTORY = 'JCPenney_Data_Original'  # Designated data folder within the current working directory\n",
    "AUGMENTED_DATA = 'Data_Additional'         # Additional data sources\n",
    " \n",
    "# A simple utility function to obtain and summarise key elements of a provided dataframe\n",
    "#\n",
    "def print_file_summary(data_frame):\n",
    "    # Create a temporary df and ensure no lists remain, so that unique items can be identified for uniquness\n",
    "    temp_df = data_frame.copy()\n",
    "    temp_df = temp_df.map(lambda cell: str(cell) if isinstance(cell, list) else cell)\n",
    "    \n",
    "    # Calculate some \n",
    "    summary_of_df = pd.DataFrame({'Count': data_frame.count(),\n",
    "                                 'Missing': data_frame.isnull().sum(), 'Empty': 0,\n",
    "                                 'Unique': temp_df.nunique(),\n",
    "                                 'Type': data_frame.dtypes, \n",
    "                                 'String': 0, 'Int': 0, 'Float': 0, 'List': 0\n",
    "                                 })\n",
    "    summary_of_df['Empty'] = (data_frame == '').sum()\n",
    "    summary_of_df['String'] = data_frame.map(lambda cell: isinstance(cell, str)).sum()\n",
    "    summary_of_df['Int'] = data_frame.map(lambda cell: isinstance(cell, int)).sum()\n",
    "    summary_of_df['Float'] = data_frame.map(lambda cell: isinstance(cell, float)).sum()\n",
    "    summary_of_df['List'] = data_frame.map(lambda cell: isinstance(cell, list)).sum()\n",
    "\n",
    "    display(summary_of_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO\n",
    "- 1. Data Exploration - Explore the data and show you understand its structure and relations\n",
    "- 2. Data Validation - Check the quality of the data. Is it complete? Are there obvious errors?\n",
    "- x. Data Preparation - Addresss the issues identified, supliment/augment the data, restructure\n",
    "    - Select Data - which to use and which to exclude .. with reasoning\n",
    "    - Clean Data - 'correct, impute, remove' ...\n",
    "    - Construct Data - derive new attributes as needed/helpful\n",
    "    - Integrate Data - new datasets, augment, other sources\n",
    "    - Format Data - reformat as needed, eg string to numeric, dates, categorical  \n",
    "\n",
    "- ?? data structure, size\n",
    "- ?? data quality, missing etc\n",
    "\n",
    "#### Data Completeness\n",
    " - Missing Data - Identify and resolve by removal or inferring. Imputation and visualisation, examining descriptive stats\n",
    "- Noisy - Random errors, eg from faulty sensors, data transmission\n",
    "- Duplicates - Identify and eliminate duplicates, redundancy. NB: Can occur after data integration\n",
    "- Inconsistency - Data items don't align, eg DOB and age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided Data Sources & Content\n",
    "\n",
    "The provided data sources for this analysis of JC Penney consists of two JSON files and three CSV files:\n",
    "- JSON: jcpenney_products, jcpenney_reviewers\n",
    "- CSV: products, reviews, users\n",
    "\n",
    "It was not immediately obvious what the relationships between the two types of data were but the json and CSV files appear to be partial duplicates of each other; also the three CSV files hold slightly less information (eg sales price is missing from the csv files). The CSV files appear to be a first attempt to extract data from the json files (eg the json products file has a JSON field holding multiple user reviews and this has looks to have been extracted to prepare the reviews.csv file).\n",
    "\n",
    "Given the above, the approach used in this analysis was to go back to the 'orginal' JSON files and work from these but with a sanity check against the three CSV files to make sure no data was missed or inconsistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources Overview - JSON\n",
    "\n",
    "It is assumed that the data is a snapshot extract of sales information from JCP databases and the bulk of this has been flattened and used to create the jcpenney_products.json file with the jcpenney_reviewers.json file providing details of individual customers.\n",
    "\n",
    "The two tables below show the data items and key counts for each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Summary for: jcpenney_products.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>6044</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_title</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6002</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>543</td>\n",
       "      <td>5620</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_price</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>2166</td>\n",
       "      <td>1037</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_price</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2063</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>636</td>\n",
       "      <td>1169</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_tree</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>636</td>\n",
       "      <td>1997</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_product_rating</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_url</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_image_urls</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>6519</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>object</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_number_reviews</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bought With</th>\n",
       "      <td>7982</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Count  Missing  Empty  Unique     Type  String   Int  \\\n",
       "uniq_id                  7982        0      0    7982   object    7982     0   \n",
       "sku                      7982        0     67    6044   object    7982     0   \n",
       "name_title               7982        0      0    6002   object    7982     0   \n",
       "description              7982        0    543    5620   object    7982     0   \n",
       "list_price               7982        0   2166    1037   object    7982     0   \n",
       "sale_price               7982        0     18    2063   object    7982     0   \n",
       "category                 7982        0    636    1169   object    7982     0   \n",
       "category_tree            7982        0    636    1997   object    7982     0   \n",
       "average_product_rating   7982        0      0     153  float64       0     0   \n",
       "product_url              7982        0      0    7982   object    7982     0   \n",
       "product_image_urls       7982        0    157    6519   object    7982     0   \n",
       "brand                    7982        0      0     721   object    7982     0   \n",
       "total_number_reviews     7982        0      0      22    int64       0  7982   \n",
       "Reviews                  7982        0      0    7982   object       0     0   \n",
       "Bought With              7982        0      0    7982   object       0     0   \n",
       "\n",
       "                        Float  List  \n",
       "uniq_id                     0     0  \n",
       "sku                         0     0  \n",
       "name_title                  0     0  \n",
       "description                 0     0  \n",
       "list_price                  0     0  \n",
       "sale_price                  0     0  \n",
       "category                    0     0  \n",
       "category_tree               0     0  \n",
       "average_product_rating   7982     0  \n",
       "product_url                 0     0  \n",
       "product_image_urls          0     0  \n",
       "brand                       0     0  \n",
       "total_number_reviews        0     0  \n",
       "Reviews                     0  7982  \n",
       "Bought With                 0  7982  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 Rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>name_title</th>\n",
       "      <th>description</th>\n",
       "      <th>list_price</th>\n",
       "      <th>sale_price</th>\n",
       "      <th>category</th>\n",
       "      <th>category_tree</th>\n",
       "      <th>average_product_rating</th>\n",
       "      <th>product_url</th>\n",
       "      <th>product_image_urls</th>\n",
       "      <th>brand</th>\n",
       "      <th>total_number_reviews</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Bought With</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>2.625</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'User': 'fsdv4141', 'Review': 'You never hav...</td>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93e5272c51d8cce02597e3ce67b7ad0a</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>alfred dunner</td>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "      <td>3.000</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'User': 'tpcu2211', 'Review': 'You never hav...</td>\n",
       "      <td>[bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013e320f2f2ec0cf5b3ff5418d688528</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>24.16</td>\n",
       "      <td>view all</td>\n",
       "      <td>jcpenney|women|view all</td>\n",
       "      <td>2.625</td>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "      <td>Alfred Dunner</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'User': 'pcfg3234', 'Review': 'You never hav...</td>\n",
       "      <td>[3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            uniq_id           sku  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       "1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       "2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
       "\n",
       "                                    name_title  \\\n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "2  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "\n",
       "                                         description list_price sale_price  \\\n",
       "0  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       "1  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       "2  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
       "\n",
       "        category                 category_tree  average_product_rating  \\\n",
       "0  alfred dunner  jcpenney|women|alfred dunner                   2.625   \n",
       "1  alfred dunner  jcpenney|women|alfred dunner                   3.000   \n",
       "2       view all       jcpenney|women|view all                   2.625   \n",
       "\n",
       "                                         product_url  \\\n",
       "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "2  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
       "\n",
       "                                  product_image_urls          brand  \\\n",
       "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "2  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
       "\n",
       "   total_number_reviews                                            Reviews  \\\n",
       "0                     8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
       "1                     8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
       "2                     8  [{'User': 'pcfg3234', 'Review': 'You never hav...   \n",
       "\n",
       "                                         Bought With  \n",
       "0  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
       "1  [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  \n",
       "2  [3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the JSON product file and examine the format and content\n",
    "# NB: Use pandas json load to directly create a dataframe\n",
    "\n",
    "# Products file source\n",
    "file_name = 'jcpenney_products.json'\n",
    "file_path = os.path.join(os.getcwd(), DATA_DIRECTORY, file_name)\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f'File not found: {file_path}')\n",
    "\n",
    "# File load into a Pandas dataframe, retained and not amended\n",
    "source_jcp_products_df = pd.read_json(file_path, lines=True)\n",
    "                    \n",
    "# Initial look at the file and data fields\n",
    "print(f'File Summary for: {file_name}')\n",
    "print_file_summary(source_jcp_products_df)\n",
    "print(f'First 3 Rows')\n",
    "display(source_jcp_products_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Summary for: jcpenney_reviewers.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Username</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviewed</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4030</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Count  Missing  Empty  Unique    Type  String  Int  Float  List\n",
       "Username   5000        0      0    4999  object    5000    0      0     0\n",
       "DOB        5000        0      0      52  object    5000    0      0     0\n",
       "State      5000        0      0      57  object    5000    0      0     0\n",
       "Reviewed   5000        0      0    4030  object       0    0      0  5000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 Rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>DOB</th>\n",
       "      <th>State</th>\n",
       "      <th>Reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>31.07.1983</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>27.07.1998</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>08.08.1950</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Username         DOB          State                            Reviewed\n",
       "0  bkpn1412  31.07.1983         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
       "1  gqjs4414  27.07.1998  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3]\n",
       "2  eehe1434  08.08.1950          Idaho                                  []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the JSON reviewers file and examine the format and content\n",
    "# NB: Use pandas json load to directly create a dataframe\n",
    "\n",
    "# Reviewers file source\n",
    "file_name = 'jcpenney_reviewers.json'\n",
    "file_path = os.path.join(os.getcwd(), DATA_DIRECTORY, file_name)\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f'File not found: {file_path}')\n",
    "\n",
    "# File load into a Pandas dataframe, retained and not amended\n",
    "source_jcp_reviewers_df = pd.read_json(file_path, lines=True)\n",
    "                    \n",
    "# Initial look at the file and data fields\n",
    "print(f'File Summary for: {file_name}')\n",
    "print_file_summary(source_jcp_reviewers_df)\n",
    "print(f'First 3 Rows')\n",
    "display(source_jcp_reviewers_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Sources Overview - CSV\n",
    "\n",
    "***TODO: Decode and compare to JSON***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation, Augmentation & Data Structure\n",
    "\n",
    "### Data Structure Summary\n",
    "\n",
    "Having examined the source data (more details and explanation in the sections below) and the areas benefiting augmentation, the following data structure was prepared ready for analysis:\n",
    "- Sales Activity - From the 7982 rows in the file jcpenney_products.json\n",
    "- Stock / Product Details - From the 6044 unique items in the file jcpenney_products.json\n",
    "- Customer Sales Reviews - XXXX unique items in the file jcpenney_products.json\n",
    "- States & Territories - List of the 57 US states and territories, with population and store totals. Augmented data from JCP and US Census. Loaded from the file JCP_Stores_State_Collated.csv\n",
    "- Customer Details - List of 5000 customers. Loaded from the file jcpenney_reviewers.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Activity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock / Product Details\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Sales Reviews\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### States & Territories\n",
    "\n",
    "Additional information collated and loaded for all US states and territories. Used to validate provided state names and augment the data provided to assist later analysis. Contains 51 states and 6 territories.\n",
    "\n",
    "The data was sourced from:\n",
    "- JCP's store locator, see [website](https://www.jcpenney.com/locations/index.html)\n",
    "- US Census Bureau, see [website](https://www.census.gov/data/tables/time-series/demo/popest/2020s-state-total.html)\n",
    "\n",
    "#### Data Content\n",
    "\n",
    "After review and vailidation the resulting dataframe, states_df, consists of:\n",
    "- territory_flag - Indicates whether a state or a territory\n",
    "- state_ISO - ISO code of the state, territory\n",
    "- state_name - Name of the state, territory\n",
    "- population - Population at 2023\n",
    "- stores_total - Total number of stores at November 2024\n",
    "\n",
    "#### Collation & Validation\n",
    "\n",
    "Loaded from the JCP_Stores_State_Collated.csv file and retained for use in validation and analysis of the JCP customer data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of States - CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>State or Territory</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_ISO</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State_Name</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Population_2023</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_Count</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Count  Missing  Empty  Unique    Type  String  Int  Float  \\\n",
       "State or Territory     57        0      0       2  object      57    0      0   \n",
       "State_ISO              57        0      0      57  object      57    0      0   \n",
       "State_Name             57        0      0      57  object      57    0      0   \n",
       "Population_2023        57        0      0      57  object      57    0      0   \n",
       "Store_Count            57        0      0      26   int64       0   57      0   \n",
       "\n",
       "                    List  \n",
       "State or Territory     0  \n",
       "State_ISO              0  \n",
       "State_Name             0  \n",
       "Population_2023        0  \n",
       "Store_Count            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State or Territory</th>\n",
       "      <th>State_ISO</th>\n",
       "      <th>State_Name</th>\n",
       "      <th>Population_2023</th>\n",
       "      <th>Store_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5,108,468</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>733,406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7,431,344</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State or Territory State_ISO State_Name Population_2023  Store_Count\n",
       "0              State        AL    Alabama       5,108,468            9\n",
       "1              State        AK     Alaska         733,406            1\n",
       "2              State        AZ    Arizona       7,431,344           17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of States - CSV\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>territory_flag</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_ISO</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>population</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stores_total</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Count  Missing  Empty  Unique    Type  String  Int  Float  \\\n",
       "territory_flag     57        0      0       2  object      57    0      0   \n",
       "state_ISO          57        0      0      57  object      57    0      0   \n",
       "state_name         57        0      0      57  object      57    0      0   \n",
       "population         57        0      0      57   int64       0   57      0   \n",
       "stores_total       57        0      0      26   int64       0   57      0   \n",
       "\n",
       "                List  \n",
       "territory_flag     0  \n",
       "state_ISO          0  \n",
       "state_name         0  \n",
       "population         0  \n",
       "stores_total       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>territory_flag</th>\n",
       "      <th>state_ISO</th>\n",
       "      <th>state_name</th>\n",
       "      <th>population</th>\n",
       "      <th>stores_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>State</td>\n",
       "      <td>AL</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>5108468</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>State</td>\n",
       "      <td>AK</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>733406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>State</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>7431344</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  territory_flag state_ISO state_name  population  stores_total\n",
       "0          State        AL    Alabama     5108468             9\n",
       "1          State        AK     Alaska      733406             1\n",
       "2          State        AZ    Arizona     7431344            17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish a list of states/territories with additional data to augment\n",
    "\n",
    "# Load the states .csv file, exit if do not exist or are invalid\n",
    "file_path = os.path.join(os.getcwd(), AUGMENTED_DATA, 'JCP_Stores_State_Collated.csv')\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f\"File not found: {file_path}\")\n",
    "states_df = pd.read_csv(file_path)\n",
    "\n",
    "# Initial look at the file and data fields\n",
    "print(f'Summary of States - CSV')\n",
    "print_file_summary(states_df)\n",
    "print(f'First 3 rows')\n",
    "display(states_df.head(3))\n",
    "\n",
    "# Rename column names & set the index on ISO\n",
    "states_df = states_df.rename(columns={'State or Territory': 'territory_flag', \n",
    "                                            'State_ISO': 'state_ISO', 'State_Name': 'state_name',\n",
    "                                            'Population_2023': 'population',\n",
    "                                            'Store_Count': 'stores_total'})\n",
    "#states_df.set_index(keys='state_ISO', inplace=True)\n",
    "\n",
    "# Convert population to int\n",
    "states_df['population'] = states_df['population'].str.replace(',', '').astype(int)\n",
    "\n",
    "# Final look at the file and data fields\n",
    "print(f'Summary of States - CSV')\n",
    "print_file_summary(states_df)\n",
    "print(f'First 3 rows')\n",
    "display(states_df.head(3))\n",
    "\n",
    "# Tidy up\n",
    "del file_path\n",
    "\n",
    "# Provide a simple state lookup of ISO for a given name\n",
    "def get_state(state_name):\n",
    "    matched_state = states_df.loc[states_df['state_name'] == state_name]\n",
    "    if len(matched_state) == 1:\n",
    "        return matched_state.iloc[0]\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Details\n",
    "\n",
    "Details of customers that have completed a review of a purchase made. With 5,000 unique customer records.\n",
    "\n",
    "#### Data Content\n",
    "\n",
    "After review and vailidation the resulting dataframe, customers_df, consists of:\n",
    "- customer_id - Unique alphanumeric id\n",
    "- DOB - Date of birth\n",
    "- state_ISO - ISO code for the state or territory. NB used as a key to the states dataframe\n",
    "- uniq_id_list - List of uniq_id to cross-reference back to the sales activity records\n",
    "    ***4030 unique vs 5000, also appear to be some empty lists***\n",
    "\n",
    "#### Collation & Validation\n",
    "\n",
    "The jcpenney_reviewers.json file was examined. As these appears to be detailig customers that have completed a review, the term 'customer' was used instead of reviewer.\n",
    "\n",
    "The following actions were taken:\n",
    "- Fields Rename: Columns renamed to be consistent with other dataframes\n",
    "- Duplicates: One customer_id was used twice. To preserve information, it was decided to keep the duplicates and give them a new unique customer_id\n",
    "- Date of Birth: Surprisingly for 5,000 customers only 52 birth dates were found. Closer examination revealed that a day, month sequence was incremented accross years; with the dates range only being from 26 July to 8 August. The dates appear to be artificially generated. Arguably this field should be dropped as it will not provide any meaningful results. However, it has been converted to a date field and retained purely so that it can be used to demonstrate later analysis\n",
    "- States: When validating against the states reference file to obtain ISO codes, 187 customers did not match due to the incorrect naming of the US Virgin Islands and US Minor Outlying Islands, so these were corrected. Only the ISO code was retained and the full state name dropped, in preference to it being looked up when required\n",
    "\n",
    "\n",
    "????\n",
    "- ***4999 in the CSV file what have they done with the duplicate***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary for customers\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Unique</th>\n",
       "      <th>Type</th>\n",
       "      <th>String</th>\n",
       "      <th>Int</th>\n",
       "      <th>Float</th>\n",
       "      <th>List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state_name</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>object</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_id_list</th>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4030</td>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Count  Missing  Empty  Unique    Type  String  Int  Float  List\n",
       "customer_id    5000        0      0    4999  object    5000    0      0     0\n",
       "DOB            5000        0      0      52  object    5000    0      0     0\n",
       "state_name     5000        0      0      57  object    5000    0      0     0\n",
       "uniq_id_list   5000        0      0    4030  object       0    0      0  5000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 rows - Renamed Columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>DOB</th>\n",
       "      <th>state_name</th>\n",
       "      <th>uniq_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>31.07.1983</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>27.07.1998</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>08.08.1950</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id         DOB     state_name                        uniq_id_list\n",
       "0    bkpn1412  31.07.1983         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
       "1    gqjs4414  27.07.1998  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3]\n",
       "2    eehe1434  08.08.1950          Idaho                                  []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Customers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>DOB</th>\n",
       "      <th>state_name</th>\n",
       "      <th>uniq_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>dqft3311</td>\n",
       "      <td>28.07.1995</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>[5f280fb338485cfc30678998a42f0a55]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>dqft3311</td>\n",
       "      <td>03.08.1969</td>\n",
       "      <td>New Mexico</td>\n",
       "      <td>[571b86d307f94e9e8d7919b551c6bb52]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id         DOB  state_name                        uniq_id_list\n",
       "731     dqft3311  28.07.1995   Tennessee  [5f280fb338485cfc30678998a42f0a55]\n",
       "2619    dqft3311  03.08.1969  New Mexico  [571b86d307f94e9e8d7919b551c6bb52]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Double-Check No Remaining Duplicated Customers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>DOB</th>\n",
       "      <th>state_name</th>\n",
       "      <th>uniq_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [customer_id, DOB, state_name, uniq_id_list]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dates Count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOB</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-08-08</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1951-08-08</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1952-08-07</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-08-07</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954-08-07</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1955-08-07</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956-08-06</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1957-08-06</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1958-08-06</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1959-08-06</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1960-08-05</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1961-08-05</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1962-08-05</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1963-08-05</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964-08-04</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1965-08-04</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1966-08-04</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1967-08-04</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1968-08-03</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1969-08-03</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1970-08-03</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1971-08-03</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1972-08-02</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1973-08-02</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1974-08-02</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1975-08-02</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1976-08-01</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1977-08-01</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1978-08-01</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1979-08-01</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1980-07-31</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1981-07-31</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1982-07-31</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1983-07-31</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1984-07-30</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1985-07-30</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1986-07-30</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1987-07-30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1988-07-29</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1989-07-29</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1990-07-29</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1991-07-29</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1992-07-28</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1993-07-28</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1994-07-28</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1995-07-28</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1996-07-27</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1997-07-27</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1998-07-27</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1999-07-27</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2000-07-26</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2001-07-26</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DOB  counts\n",
       "0  1950-08-08      99\n",
       "1  1951-08-08      95\n",
       "2  1952-08-07     103\n",
       "3  1953-08-07     112\n",
       "4  1954-08-07      79\n",
       "5  1955-08-07      93\n",
       "6  1956-08-06      96\n",
       "7  1957-08-06      93\n",
       "8  1958-08-06      96\n",
       "9  1959-08-06      94\n",
       "10 1960-08-05     107\n",
       "11 1961-08-05     101\n",
       "12 1962-08-05     106\n",
       "13 1963-08-05     106\n",
       "14 1964-08-04     107\n",
       "15 1965-08-04     106\n",
       "16 1966-08-04      94\n",
       "17 1967-08-04      90\n",
       "18 1968-08-03      91\n",
       "19 1969-08-03      99\n",
       "20 1970-08-03     101\n",
       "21 1971-08-03      90\n",
       "22 1972-08-02      91\n",
       "23 1973-08-02     102\n",
       "24 1974-08-02     102\n",
       "25 1975-08-02     106\n",
       "26 1976-08-01      87\n",
       "27 1977-08-01      97\n",
       "28 1978-08-01      79\n",
       "29 1979-08-01     106\n",
       "30 1980-07-31      99\n",
       "31 1981-07-31      85\n",
       "32 1982-07-31      98\n",
       "33 1983-07-31      99\n",
       "34 1984-07-30      80\n",
       "35 1985-07-30     100\n",
       "36 1986-07-30      83\n",
       "37 1987-07-30      99\n",
       "38 1988-07-29     100\n",
       "39 1989-07-29      81\n",
       "40 1990-07-29     103\n",
       "41 1991-07-29     104\n",
       "42 1992-07-28     101\n",
       "43 1993-07-28      96\n",
       "44 1994-07-28      86\n",
       "45 1995-07-28      95\n",
       "46 1996-07-27      81\n",
       "47 1997-07-27      97\n",
       "48 1998-07-27     111\n",
       "49 1999-07-27     104\n",
       "50 2000-07-26      90\n",
       "51 2001-07-26      80"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched States:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>wjfh4432</td>\n",
       "      <td>Minor Outlying Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ulkz1412</td>\n",
       "      <td>Minor Outlying Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>bsqg4331</td>\n",
       "      <td>Minor Outlying Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>bbiv3413</td>\n",
       "      <td>Minor Outlying Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>surt1311</td>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>ypcn2342</td>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>lric2324</td>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>okun1224</td>\n",
       "      <td>Minor Outlying Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>kjgm1311</td>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>gjed1211</td>\n",
       "      <td>U.S. Virgin Islands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     customer_id              state_name\n",
       "29      wjfh4432  Minor Outlying Islands\n",
       "104     ulkz1412  Minor Outlying Islands\n",
       "106     bsqg4331  Minor Outlying Islands\n",
       "203     bbiv3413  Minor Outlying Islands\n",
       "215     surt1311     U.S. Virgin Islands\n",
       "...          ...                     ...\n",
       "4872    ypcn2342     U.S. Virgin Islands\n",
       "4940    lric2324     U.S. Virgin Islands\n",
       "4960    okun1224  Minor Outlying Islands\n",
       "4970    kjgm1311     U.S. Virgin Islands\n",
       "4976    gjed1211     U.S. Virgin Islands\n",
       "\n",
       "[187 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched States:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [customer_id, state_name]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers by State:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_ISO</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AL</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AR</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AZ</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CA</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CO</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CT</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DC</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FL</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GA</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GU</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HI</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>IA</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ID</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>IL</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>IN</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KS</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KY</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LA</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MA</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MD</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ME</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MI</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MN</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MO</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MP</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MS</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MT</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NC</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ND</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NE</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NH</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NJ</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NM</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NV</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NY</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>OH</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>OK</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>OR</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>PA</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>PR</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RI</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SC</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SD</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TN</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TX</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UM</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UT</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VA</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>VI</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>VT</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>WA</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>WI</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>WV</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>WY</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   state_ISO  counts\n",
       "0         AK      94\n",
       "1         AL      95\n",
       "2         AR      92\n",
       "3         AS      86\n",
       "4         AZ      71\n",
       "5         CA      99\n",
       "6         CO      85\n",
       "7         CT      82\n",
       "8         DC      83\n",
       "9         DE     106\n",
       "10        FL      89\n",
       "11        GA      79\n",
       "12        GU      73\n",
       "13        HI      88\n",
       "14        IA      94\n",
       "15        ID      79\n",
       "16        IL      69\n",
       "17        IN      86\n",
       "18        KS      90\n",
       "19        KY      99\n",
       "20        LA      80\n",
       "21        MA     107\n",
       "22        MD      77\n",
       "23        ME      94\n",
       "24        MI      76\n",
       "25        MN      77\n",
       "26        MO      84\n",
       "27        MP     102\n",
       "28        MS      94\n",
       "29        MT      97\n",
       "30        NC      68\n",
       "31        ND      85\n",
       "32        NE      90\n",
       "33        NH      83\n",
       "34        NJ     101\n",
       "35        NM      96\n",
       "36        NV      90\n",
       "37        NY      83\n",
       "38        OH      81\n",
       "39        OK     100\n",
       "40        OR      96\n",
       "41        PA      86\n",
       "42        PR      83\n",
       "43        RI      93\n",
       "44        SC      77\n",
       "45        SD      79\n",
       "46        TN      89\n",
       "47        TX      83\n",
       "48        UM      92\n",
       "49        UT      80\n",
       "50        VA      96\n",
       "51        VI      95\n",
       "52        VT     103\n",
       "53        WA      94\n",
       "54        WI      84\n",
       "55        WV      80\n",
       "56        WY      86"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Establish a customer details dataframe \n",
    "\n",
    "# Create a new dataframe for all cutomer reviews\n",
    "customers_df = source_jcp_reviewers_df.copy()\n",
    "\n",
    "# Rename customer column names and validate content for each\n",
    "customers_df = customers_df.rename(columns={'Username': 'customer_id', \n",
    "                                            'State': 'state_name',\n",
    "                                            'Reviewed': 'uniq_id_list'})\n",
    "\n",
    "# Print the file and data fields\n",
    "print(f'Summary for customers')\n",
    "print_file_summary(customers_df)\n",
    "print(f'First 3 rows - Renamed Columns')\n",
    "display(customers_df.head(3))\n",
    "\n",
    "# Identify duplicate customers \n",
    "duplicates_flag = customers_df.duplicated(subset=['customer_id'], keep=False)\n",
    "duplicated = customers_df[duplicates_flag]\n",
    "print(f'Duplicated Customers:')\n",
    "display(duplicated)\n",
    "\n",
    "# Replace duplicates with new customer_id 'DUPnnnxxxxxxx' to preserve \n",
    "# Use itertuples as faster for larger datasets\n",
    "dup_count = 0\n",
    "for row in duplicated.itertuples():   \n",
    "    dup_count += 1\n",
    "    new_id = 'DUP' + str(dup_count).zfill(3) + row.customer_id     \n",
    "    customers_df.at[row.Index, 'customer_id'] = new_id\n",
    "\n",
    "# Double check no duplicates remain\n",
    "duplicates_flag = customers_df.duplicated(subset=['customer_id'], keep=False)\n",
    "duplicated = customers_df[duplicates_flag]\n",
    "print(f'Double-Check No Remaining Duplicated Customers:')\n",
    "display(duplicated)\n",
    "\n",
    "# DOB convert to date format and examine the dates used\n",
    "customers_df['DOB'] = pd.to_datetime(customers_df['DOB'], dayfirst=True, errors='coerce')\n",
    "dates = customers_df.groupby('DOB').size().reset_index(name='counts')\n",
    "print(f'Dates Count:')\n",
    "display(dates)\n",
    "# Drop the date as looks artifically generated and so of no real use in later analysis\n",
    "# customers_df = customers_df.drop('DOB', axis=1)\n",
    "\n",
    "# States validation - lookup ISO codes, add to customer data and check for invalid matches\n",
    "customers_df['state_ISO'] = customers_df['state_name'].apply(lambda x: get_state(x)['state_ISO'] if get_state(x) is not None else None)\n",
    "unmatched_states = customers_df[customers_df['state_ISO'].isnull()]\n",
    "print(f'Unmatched States:')\n",
    "display(unmatched_states[['customer_id', 'state_name']])\n",
    "\n",
    "# Names mismatch for US Virgin Islands and US Minor Outlying Islands\n",
    "customers_df.replace('U.S. Virgin Islands', 'US Virgin Islands', inplace=True)\n",
    "customers_df.replace('Minor Outlying Islands', 'US Minor Outlying Islands', inplace=True)\n",
    "\n",
    "# Repeat the checks & drop state_name if all ISO populated\n",
    "customers_df['state_ISO'] = customers_df['state_name'].apply(lambda x: get_state(x)['state_ISO'] if get_state(x) is not None else None)\n",
    "unmatched_states = customers_df[customers_df['state_ISO'].isnull()]\n",
    "print(f'Unmatched States:')\n",
    "display(unmatched_states[['customer_id', 'state_name']])\n",
    "\n",
    "# Drop the state name, rely on the ISO code and states lookup\n",
    "if len(unmatched_states) != 0:\n",
    "    raise Exception(f'Cannot match: {len(unmatched_states)} states')\n",
    "customers_df = customers_df.drop('state_name', axis=1)\n",
    "\n",
    "# Visual check on state details\n",
    "states = customers_df.groupby('state_ISO').size().reset_index(name='counts')\n",
    "print(f'Customers by State:')\n",
    "display(states)\n",
    "\n",
    "# Reviewed validate\n",
    "# TODO: x-check these to sales activity and to reviews to make sure consistent\n",
    "\n",
    "# Tidy up\n",
    "del duplicates_flag, duplicated, dup_count, new_id, row\n",
    "del dates\n",
    "del unmatched_states, states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structure\n",
    "\n",
    "\n",
    "Sales Activity - 7982 rows in the file jcpenney_products.json\n",
    "- uniq_id: this uniquely identifies each of the 7982 rows. A random string\n",
    "- list_price: assumed to be the price at the point of sale in $\n",
    "    ***?? prices consistent accross channels, any pattern?, 18 missing ***\n",
    "    *** convert to numeric**\n",
    "- category_tree: breakdown of the stock catgeorisation eg 'jcpenny|women|skechers' \n",
    "- category: lowest level of category \n",
    "    *** drop this? why unique 1169 vs 1997 for the treee also ?? not same match to SKU etc eg the use of 'view all' ?? ***\n",
    "- average_product_rating: rating 1 to 5 \n",
    "    *** a float with some wierd values .. should be categorical? convert? ***,\n",
    "    *** is this a calculated average from individual reviews? check***\n",
    "- product_url: link to website product details \n",
    "    *** 7982 And these are unique to the review, not the product ... why? ***\n",
    "    *** need us vpn to use this? ***\n",
    "- product_image_urls: link to product image \n",
    "    *** 6519, more images than product number, less than product URL ***\n",
    "- Bought with: series of items linked using the uniq_id \n",
    "    *** check these link up? and rename ***\n",
    "    ***what is is useful for?***\n",
    "\n",
    "Stock / Product - 6044 unique items in the file jcpenney_products.json\n",
    "- sku: a unique 'Stock Keeping Unit', format 'xxnnnnnnnnnn', 6044 discrete values\n",
    "    ***?? are all references valid format, 67 seem odd or blank or not standard format***\n",
    "- name_title: name of the stock item\n",
    "    ***?? uniques count about 38 less than SKU***\n",
    "- description: long description of the item\n",
    "    ***?? uniques count about 400 less than name***\n",
    "- list_price: assumed to be the standard item price in $\n",
    "    ***?? prices appear to be different for some stock, 2166 missing ***\n",
    "    *** convert to numeric**\n",
    "- brand: manufacturer brand name eg 'Alfred Dunner'\n",
    "\n",
    "Customer Reviews - unique items in the file jcpenney_products.json\n",
    "- total_number_reviews: number of customer reviews for each uniq_id / Sales Channel Activity\n",
    "    *** is this needed, or just for a cross-check later? convert to numeric**\n",
    "- Reviews: a json item with several customer reviews, each with: user, review text, score (1 to 5) \n",
    "\n",
    "\n",
    "\n",
    "#### Links\n",
    "?? Link/Cross-Ref\n",
    "- 'Stock Keeping Unit' (https://en.wikipedia.org/wiki/Stock_keeping_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sales Activity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock / Products\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Reviews\n",
    "\n",
    "In the \"jcpenney_products.json\" file the series of JSON encoded review details were extracted and a new customer reviews dataframe was created, with individual review records linked back to the sales activiy using the uniq_id. The table below summarises the fields decoded and key counts.\n",
    "\n",
    "There are a total of 39,063 reviews but only 29,464 appear to be unique review comments. Further analysis found that 15,535 (40%) of reviews were used by several customers, worst case being several instances of 18 customers using the same comments. This could be because the sample data has been automaticaly generated or that customer ids are being created to generate false reviews. This data has not been dropped from the dataset, although later sentiment analysis of the reviews could be misleading.\n",
    "\n",
    "The scores for reviews in the CSV file have a large number of zero vslues (11,265 out of 39,063) and a quick examination showed that many scores differ between the JSON and CSV source. Therefore the \"reviews.CSV\" data source was rejected and only the JSON source was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish an initial customer reviews dataframe\n",
    "# By extracting the series of JSON reviews originaly in the jcpenney_products.json \n",
    "\n",
    "# Create a new dataframe for all cutomer reviews\n",
    "customer_reviews_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through all rows of the orgonal products data, to extract and decode the series of JSON data\n",
    "# Create customer review rows, each using a foreign key uniq_id for the relevant sales activity\n",
    "# TODO: This takes 4 seconds to run, replace with a more efficient approach\n",
    "for next_row in source_jcp_products_df.itertuples(index=False):\n",
    "    temp_reviews = next_row.Reviews\n",
    "    #print(f'UI: {next_row.uniq_id}, {temp_reviews}, {type(temp_reviews)}')\n",
    "    temp_dict_string = json.dumps(temp_reviews)\n",
    "    temp_reviews_df = pd.DataFrame(json.loads(temp_dict_string))\n",
    "    temp_reviews_df.insert(0, 'uniq_id', next_row.uniq_id)\n",
    "    #print(temp_reviews_df)\n",
    "    customer_reviews_df = pd.concat([customer_reviews_df, temp_reviews_df])\n",
    "\n",
    "# Cross-check the customer_id to the customers data frame to make sure all exist\n",
    "if not customer_reviews_df['User'].isin(customers_df['customer_id']).all():\n",
    "    print(f'Error: Not all customers setup in customers list')\n",
    "\n",
    "# Tidy up\n",
    "del temp_reviews\n",
    "del temp_dict_string\n",
    "del temp_reviews_df\n",
    "\n",
    "# Rename customer column names and validate content for each\n",
    "customer_reviews_df = customer_reviews_df.rename(columns={'User': 'customer_id', \n",
    "                                                          'Review': 'review', 'Score': 'score'})\n",
    "\n",
    "# Initial look at the file and data fields\n",
    "print(f'Summary for customer reviews')\n",
    "print_file_summary(customer_reviews_df)\n",
    "print(f'First 3 rows')\n",
    "display(customer_reviews_df.head(3))\n",
    "\n",
    "# ?? create products ... sales activity file without reviews\n",
    "# Ensure a valid customer record exists in the customers dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how many reviews are duplicates and how many customers are linked to these\n",
    "\n",
    "duplicates_by_customer = customer_reviews_df.groupby('review')['customer_id'].size().reset_index(name='cust_count')\n",
    "reviews_duplicated = duplicates_by_customer.groupby('cust_count').count().reset_index()\n",
    "\n",
    "count_reviews_single = reviews_duplicated[reviews_duplicated['cust_count'] == 1]\n",
    "count_reviews_duplicated = len(customer_reviews_df) - count_reviews_single['review'].sum()\n",
    "max_duplicates = reviews_duplicated['cust_count'].max()\n",
    "\n",
    "print(f'Out of a total of {len(customer_reviews_df)} reviews {count_reviews_duplicated} are duplicates.')\n",
    "print(f'Or approximately {((count_reviews_duplicated/len(customer_reviews_df)) * 100):.0f}%')\n",
    "print(f'Several worst case situations with {max_duplicates} customers using the same review comments.')\n",
    "\n",
    "# Tidy up\n",
    "del duplicates_by_customer\n",
    "del reviews_duplicated\n",
    "del count_reviews_single\n",
    "del count_reviews_duplicated\n",
    "del max_duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV reviews file to cross-check against the data extracted from the JSON sourced reviews\n",
    "\n",
    "# Load the reviews .csv file, exit if do not exist or are invalid\n",
    "file_path = os.path.join(os.getcwd(), DATA_DIRECTORY, 'reviews.csv')\n",
    "if not os.path.isfile(file_path):\n",
    "    raise Exception(f\"File not found: {file_path}\")\n",
    "source_reviewsCSV_df = pd.read_csv(file_path)\n",
    "\n",
    "# Initial look at the file and data fields\n",
    "print(f'Summary for customer reviews - CSV')\n",
    "print_file_summary(source_reviewsCSV_df)\n",
    "print(f'First 3 rows')\n",
    "display(source_reviewsCSV_df.head(3))\n",
    "\n",
    "# Scores look very different\n",
    "\n",
    "count_zero_scores = source_reviewsCSV_df[source_reviewsCSV_df['Score'] == 0]['Score'].count()\n",
    "count_zero_scoresJSON = customer_reviews_df[customer_reviews_df['score'] == 0]['score'].count()\n",
    "\n",
    "print(f'Compare JSON sourced review vs CSV file source')\n",
    "print(f'Count:  {len(customer_reviews_df)} vs {len(source_reviewsCSV_df)}')\n",
    "print(f'Scores with zero: {count_zero_scoresJSON:.0f} vs {count_zero_scores:.0f}')\n",
    "print(f'Mean:  {customer_reviews_df['score'].mean():.1f} vs {source_reviewsCSV_df['Score'].mean():.1f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis of reviews\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_categorise(sentiment):\n",
    "    '''\n",
    "    Positive: Compound score >= 0.05\n",
    "    Neutral: Compound score > -0.05 and < 0.05\n",
    "    Negative: Compound score <= -0.05\n",
    "    '''\n",
    "    if sentiment <= -0.05:\n",
    "        return 1\n",
    "    elif sentiment < 0.05:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "review_sentiments = [analyser.polarity_scores(review_text)['compound'] for review_text in customer_reviews_df['review']]\n",
    "customer_reviews_df['sentimentC'] = [sentiment_categorise(x) for x in review_sentiments]\n",
    "customer_reviews_df['sentiment'] = review_sentiments\n",
    "\n",
    "# TODO: Appears to be an inconsistent use of score, some appear to have 1 as best whilst others using 5 as best\n",
    "# TODO: Classify sentiment anlaysis as good, bad, neutral or 1 3 5? Correlate/fit with score? Evidence to support above?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "\n",
    "- 4993 users x-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualisation\n",
    "\n",
    " 3. Data Visualisation - Gain an overall understanding of the data with visualisations\n",
    "\n",
    "- Initial review, plots etc\n",
    "- Initial observations, insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    " 4. Data Analysis = Set some questions and use the data to answer them\n",
    " 5. Data Augmentation - Add new data from another source to bring new insights to the data you already have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "See the CRISP-DM in the intro\n",
    "- https://www.datascience-pm.com/crisp-dm-2/\n",
    "- (Ncr et al., 1999) ........ Ncr, P.C. et al. (1999) ‘CRISP-DM 1.0’."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
